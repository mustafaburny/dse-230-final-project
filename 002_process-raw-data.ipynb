{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c961e009-0428-468e-98fe-d74c5a3ce5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import tqdm.auto\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import dask.distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0072f-8985-4b64-af8b-1d115f122c0e",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e67bfdc-e2cd-4480-93e2-1662ca659800",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_DURATION_SECONDS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed46df9-13b9-4ebb-8a6f-f32db1b84eb0",
   "metadata": {},
   "source": [
    "#### Start a Dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a18064e-8ab2-4315-b604-e12d09b7dc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:59961</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>24</li>\n",
       "  <li><b>Memory: </b>63.93 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:59961' processes=6 threads=24, memory=63.93 GiB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = dask.distributed.Client()\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b9808b-70a2-47f8-b737-fa974864931b",
   "metadata": {},
   "source": [
    "#### Generate Windowed Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4cd4a40-dae6-4ecd-bfd5-107f00dc64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subject_raw_data_files(subject_id):\n",
    "    activity_map = pd.read_table(\n",
    "        'wisdm-dataset/activity_key.txt',\n",
    "        sep = ' = ',\n",
    "        header = None,\n",
    "        engine = 'python',\n",
    "        names = ['activity_name', 'activity_id']\n",
    "    ).set_index('activity_id')['activity_name'].to_dict()\n",
    "    \n",
    "    def process_raw_data_file(sensor, device):\n",
    "        df = pd.read_table(\n",
    "            f'wisdm-dataset/raw/{device}/{sensor}/data_{subject_id}_{sensor}_{device}.txt',\n",
    "            sep = ',',\n",
    "            header = None, \n",
    "            names = ['subject_id', 'activity_id', 'timestamp', 'x', 'y', 'z'],\n",
    "        )\n",
    "\n",
    "        # The end of each line has a semi-colon which is being stored in the \"z\" column; remove this semi-colon.\n",
    "        df['z'] = df['z'].str[0:-1].astype(float)\n",
    "\n",
    "        # Rename x, y, z columns\n",
    "        df.rename(columns={'x': f'{sensor}_{device}_x', 'y': f'{sensor}_{device}_y', 'z': f'{sensor}_{device}_z'}, inplace=True)\n",
    "\n",
    "        # Map activity_id to activity name\n",
    "        df['activity_name'] = df['activity_id'].map(activity_map)\n",
    "\n",
    "        # Calculate t0 (unique for each subject, device, sensor, and activity)\n",
    "        df = df.merge(df.groupby(['activity_id'])['timestamp'].min().reset_index().rename(columns={'timestamp': 't0'}))\n",
    "\n",
    "        # Calculate t (from t0) (Units = milliseconds)\n",
    "        df['t_ms'] = ( df['timestamp'] - df['t0'] ) / 1_000_000\n",
    "\n",
    "        # Round t_ms rounded to nearest 50 ms (because sensor sampling rate = 20Hz)\n",
    "        base = 50\n",
    "        df['t_ms_rounded'] = df['t_ms'].apply(lambda x: base * round(float(x) / base)).astype('int')\n",
    "\n",
    "        # Compute absolute delta between t_ms and t_ms_rounded\n",
    "        df['abs_delta_ms'] = ( df['t_ms'] - df['t_ms_rounded'] ).abs()\n",
    "\n",
    "        # Sort by time\n",
    "        df.sort_values(['activity_id', 't_ms', 'abs_delta_ms'], ascending=[True, True, False], inplace=True)\n",
    "\n",
    "        # Remove duplicates (for each activity, by t_ms_rounded)\n",
    "        df.drop_duplicates(subset=['activity_id', 't_ms_rounded'], keep='first', inplace=True)\n",
    "\n",
    "        # Calculate segment sequence number\n",
    "        df['segment_sequence_number'] = np.floor(df['t_ms'] / 1_000 / WINDOW_DURATION_SECONDS).astype(int) + 1\n",
    "\n",
    "        # Remove irrelevant columns\n",
    "        df.drop(columns=['timestamp', 't0', 't_ms', 'abs_delta_ms'], inplace=True)\n",
    "\n",
    "        activity_dfs = []\n",
    "        # Add dataframe to subject_dfs\n",
    "        for activity_id in df['activity_id'].unique():\n",
    "            activity_df = df[df['activity_id'] == activity_id].copy()\n",
    "            assert activity_df['t_ms_rounded'].is_monotonic_increasing\n",
    "            activity_df.set_index(['subject_id', 'activity_id', 'activity_name', 'segment_sequence_number', 't_ms_rounded'], inplace=True)\n",
    "            activity_dfs.append(activity_df)\n",
    "\n",
    "        return pd.concat(activity_dfs, axis=0)\n",
    "    \n",
    "    subject_dfs = []\n",
    "    for sensor in ('accel', 'gyro'):\n",
    "        for device in ('phone', 'watch'):\n",
    "            subject_dfs.append(process_raw_data_file(sensor, device))\n",
    "            \n",
    "    # In subject_dfs,\n",
    "    #   - The 1st dataframe is accel_phone\n",
    "    #   - The 2nd dataframe is accel_watch\n",
    "    #   - The 3rd dataframe is gyro_phone\n",
    "    #   - The 4th dataframe is gyro_watch\n",
    "    return pd.concat(subject_dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff2166cf-679a-42fd-b7dc-9170bfa15b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115431c3d459453f91d758d30d5c0910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Submitting Jobs to Dask Client:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for all Jobs to Complete...done!\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 3298350 entries, (1600, 'A', 'walking', 1, 0) to (1650, 'S', 'folding', 12, 180000)\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   accel_phone_x  float64\n",
      " 1   accel_phone_y  float64\n",
      " 2   accel_phone_z  float64\n",
      " 3   accel_watch_x  float64\n",
      " 4   accel_watch_y  float64\n",
      " 5   accel_watch_z  float64\n",
      " 6   gyro_phone_x   float64\n",
      " 7   gyro_phone_y   float64\n",
      " 8   gyro_phone_z   float64\n",
      " 9   gyro_watch_x   float64\n",
      " 10  gyro_watch_y   float64\n",
      " 11  gyro_watch_z   float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 321.0+ MB\n"
     ]
    }
   ],
   "source": [
    "subject_ids = pd.Series(\n",
    "    glob.glob('wisdm-dataset/raw/*/*/*.txt', recursive=True)\n",
    ").str.extract(r'^.+data_(\\d+?)_.+$', expand=False).astype('int').sort_values().unique()\n",
    "\n",
    "subject_data_futures = []\n",
    "for subject_id in tqdm.auto.tqdm(subject_ids, desc='Submitting Jobs to Dask Client'):\n",
    "    subject_data_futures.append(client.submit(process_subject_raw_data_files, subject_id))\n",
    "\n",
    "print('Waiting for all Jobs to Complete...', end='')\n",
    "df = pd.concat(client.gather(subject_data_futures), axis=0)\n",
    "print('done!' + '\\n')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d3ebe4f-7689-4fa4-9eef-5f786dd20e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 3298350 entries, (1600, 'A', 'walking', 1, 0, 1) to (1650, 'S', 'folding', 12, 180000, 11138)\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   accel_phone_x  float64\n",
      " 1   accel_phone_y  float64\n",
      " 2   accel_phone_z  float64\n",
      " 3   accel_watch_x  float64\n",
      " 4   accel_watch_y  float64\n",
      " 5   accel_watch_z  float64\n",
      " 6   gyro_phone_x   float64\n",
      " 7   gyro_phone_y   float64\n",
      " 8   gyro_phone_z   float64\n",
      " 9   gyro_watch_x   float64\n",
      " 10  gyro_watch_y   float64\n",
      " 11  gyro_watch_z   float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 327.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Add unique segment IDs to each time segment\n",
    "segment_ids = pd.Series(index=df.index.droplevel(4).drop_duplicates(), data=np.arange(len(df.index.droplevel(4).drop_duplicates()))+1)\n",
    "segment_ids.name = 'segment_id'\n",
    "\n",
    "df = pd.merge(\n",
    "    left = df,\n",
    "    right = segment_ids,\n",
    "    how = 'left',\n",
    "    left_index = True,\n",
    "    right_index = True,\n",
    ")\n",
    "\n",
    "df.set_index('segment_id', append=True, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d75abc-0ab8-41b2-9060-14a29cfa52b4",
   "metadata": {},
   "source": [
    "#### Write `df` to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8592f11-8b43-4270-80d6-704df9b6ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('processed_raw_data.parquet', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd4cde-42c0-46d9-9371-6bc5f2e4c581",
   "metadata": {},
   "source": [
    "#### Shutdown Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "939accc7-7e93-4072-8b19-33d289acd254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python39564bit90b0c75a1c4348008952656302cab51b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
